{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d626b28d-9ebe-451a-ae70-32cf6563f42f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30f5fd32-d6b5-4395-a2c4-cef140737c05",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = \"../data/processed/adult_balanced.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "add7f2f6-c4a6-46a9-b075-c3cd16844419",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "089977b3-027b-4a40-990e-a0e81f56458b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>fnlwgt</th>\n",
       "      <th>education.num</th>\n",
       "      <th>capital.gain</th>\n",
       "      <th>capital.loss</th>\n",
       "      <th>hours.per.week</th>\n",
       "      <th>workclass_Local-gov</th>\n",
       "      <th>workclass_Private</th>\n",
       "      <th>workclass_Self-emp-inc</th>\n",
       "      <th>workclass_Self-emp-not-inc</th>\n",
       "      <th>...</th>\n",
       "      <th>native.country_Puerto-Rico</th>\n",
       "      <th>native.country_Scotland</th>\n",
       "      <th>native.country_South</th>\n",
       "      <th>native.country_Taiwan</th>\n",
       "      <th>native.country_Thailand</th>\n",
       "      <th>native.country_Trinadad&amp;Tobago</th>\n",
       "      <th>native.country_United-States</th>\n",
       "      <th>native.country_Vietnam</th>\n",
       "      <th>native.country_Yugoslavia</th>\n",
       "      <th>income</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3.316630</td>\n",
       "      <td>-0.538790</td>\n",
       "      <td>-0.439738</td>\n",
       "      <td>-0.147445</td>\n",
       "      <td>10.555814</td>\n",
       "      <td>-1.914161</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.184831</td>\n",
       "      <td>-0.467906</td>\n",
       "      <td>-2.400559</td>\n",
       "      <td>-0.147445</td>\n",
       "      <td>9.427915</td>\n",
       "      <td>-0.077734</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.195067</td>\n",
       "      <td>0.708645</td>\n",
       "      <td>-0.047574</td>\n",
       "      <td>-0.147445</td>\n",
       "      <td>9.427915</td>\n",
       "      <td>-0.077734</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.337883</td>\n",
       "      <td>0.256222</td>\n",
       "      <td>-0.439738</td>\n",
       "      <td>-0.147445</td>\n",
       "      <td>9.106365</td>\n",
       "      <td>0.339636</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.033340</td>\n",
       "      <td>-0.370964</td>\n",
       "      <td>-1.616231</td>\n",
       "      <td>-0.147445</td>\n",
       "      <td>9.106365</td>\n",
       "      <td>-0.077734</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45303</th>\n",
       "      <td>0.507883</td>\n",
       "      <td>-0.802791</td>\n",
       "      <td>-0.439738</td>\n",
       "      <td>-0.147445</td>\n",
       "      <td>-0.218586</td>\n",
       "      <td>-0.077734</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45304</th>\n",
       "      <td>1.461288</td>\n",
       "      <td>0.333465</td>\n",
       "      <td>-0.439738</td>\n",
       "      <td>0.110457</td>\n",
       "      <td>-0.218586</td>\n",
       "      <td>1.591745</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45305</th>\n",
       "      <td>0.220682</td>\n",
       "      <td>-0.344527</td>\n",
       "      <td>-0.699963</td>\n",
       "      <td>-0.147445</td>\n",
       "      <td>-0.218586</td>\n",
       "      <td>-0.077734</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45306</th>\n",
       "      <td>1.056800</td>\n",
       "      <td>0.668374</td>\n",
       "      <td>1.128918</td>\n",
       "      <td>-0.147445</td>\n",
       "      <td>-0.218586</td>\n",
       "      <td>0.757005</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45307</th>\n",
       "      <td>0.215048</td>\n",
       "      <td>-0.587106</td>\n",
       "      <td>1.128918</td>\n",
       "      <td>-0.147445</td>\n",
       "      <td>-0.218586</td>\n",
       "      <td>0.442247</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>45308 rows × 97 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            age    fnlwgt  education.num  capital.gain  capital.loss  \\\n",
       "0      3.316630 -0.538790      -0.439738     -0.147445     10.555814   \n",
       "1      1.184831 -0.467906      -2.400559     -0.147445      9.427915   \n",
       "2      0.195067  0.708645      -0.047574     -0.147445      9.427915   \n",
       "3     -0.337883  0.256222      -0.439738     -0.147445      9.106365   \n",
       "4     -0.033340 -0.370964      -1.616231     -0.147445      9.106365   \n",
       "...         ...       ...            ...           ...           ...   \n",
       "45303  0.507883 -0.802791      -0.439738     -0.147445     -0.218586   \n",
       "45304  1.461288  0.333465      -0.439738      0.110457     -0.218586   \n",
       "45305  0.220682 -0.344527      -0.699963     -0.147445     -0.218586   \n",
       "45306  1.056800  0.668374       1.128918     -0.147445     -0.218586   \n",
       "45307  0.215048 -0.587106       1.128918     -0.147445     -0.218586   \n",
       "\n",
       "       hours.per.week  workclass_Local-gov  workclass_Private  \\\n",
       "0           -1.914161                False               True   \n",
       "1           -0.077734                False               True   \n",
       "2           -0.077734                False               True   \n",
       "3            0.339636                False               True   \n",
       "4           -0.077734                False               True   \n",
       "...               ...                  ...                ...   \n",
       "45303       -0.077734                False               True   \n",
       "45304        1.591745                False               True   \n",
       "45305       -0.077734                False               True   \n",
       "45306        0.757005                False               True   \n",
       "45307        0.442247                False               True   \n",
       "\n",
       "       workclass_Self-emp-inc  workclass_Self-emp-not-inc  ...  \\\n",
       "0                       False                       False  ...   \n",
       "1                       False                       False  ...   \n",
       "2                       False                       False  ...   \n",
       "3                       False                       False  ...   \n",
       "4                       False                       False  ...   \n",
       "...                       ...                         ...  ...   \n",
       "45303                   False                       False  ...   \n",
       "45304                    True                       False  ...   \n",
       "45305                   False                       False  ...   \n",
       "45306                   False                       False  ...   \n",
       "45307                   False                       False  ...   \n",
       "\n",
       "       native.country_Puerto-Rico  native.country_Scotland  \\\n",
       "0                           False                    False   \n",
       "1                           False                    False   \n",
       "2                           False                    False   \n",
       "3                           False                    False   \n",
       "4                           False                    False   \n",
       "...                           ...                      ...   \n",
       "45303                       False                    False   \n",
       "45304                       False                    False   \n",
       "45305                       False                    False   \n",
       "45306                       False                    False   \n",
       "45307                       False                    False   \n",
       "\n",
       "       native.country_South  native.country_Taiwan  native.country_Thailand  \\\n",
       "0                     False                  False                    False   \n",
       "1                     False                  False                    False   \n",
       "2                     False                  False                    False   \n",
       "3                     False                  False                    False   \n",
       "4                     False                  False                    False   \n",
       "...                     ...                    ...                      ...   \n",
       "45303                 False                  False                    False   \n",
       "45304                 False                  False                    False   \n",
       "45305                 False                  False                    False   \n",
       "45306                 False                  False                    False   \n",
       "45307                 False                  False                    False   \n",
       "\n",
       "       native.country_Trinadad&Tobago  native.country_United-States  \\\n",
       "0                               False                          True   \n",
       "1                               False                          True   \n",
       "2                               False                          True   \n",
       "3                               False                          True   \n",
       "4                               False                          True   \n",
       "...                               ...                           ...   \n",
       "45303                           False                          True   \n",
       "45304                           False                          True   \n",
       "45305                           False                          True   \n",
       "45306                           False                          True   \n",
       "45307                           False                          True   \n",
       "\n",
       "       native.country_Vietnam  native.country_Yugoslavia  income  \n",
       "0                       False                      False       0  \n",
       "1                       False                      False       0  \n",
       "2                       False                      False       0  \n",
       "3                       False                      False       0  \n",
       "4                       False                      False       0  \n",
       "...                       ...                        ...     ...  \n",
       "45303                   False                      False       1  \n",
       "45304                   False                      False       1  \n",
       "45305                   False                      False       1  \n",
       "45306                   False                      False       1  \n",
       "45307                   False                      False       1  \n",
       "\n",
       "[45308 rows x 97 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b48995b6-2689-44d5-bb5d-ba56ecee9c54",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop('income', axis=1)\n",
    "y = df['income']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba026fba-feab-4909-8ad2-b7cea0742656",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c976f0d-3cf1-49ee-a754-f87923abec95",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train shape: (36246, 96), Test shape: (9062, 96)\n",
      "Train target distribution:\n",
      "income\n",
      "1    50.0\n",
      "0    50.0\n",
      "Name: proportion, dtype: float64\n",
      "Test target distribution:\n",
      "income\n",
      "1    50.0\n",
      "0    50.0\n",
      "Name: proportion, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print(f\"Train shape: {X_train.shape}, Test shape: {X_test.shape}\")\n",
    "print(f\"Train target distribution:\\n{y_train.value_counts(normalize=True) * 100}\")\n",
    "print(f\"Test target distribution:\\n{y_test.value_counts(normalize=True) * 100}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a401458-4c45-400e-a9a4-7c8bf47388d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0b4fcfd-3899-460c-8f41-bca76610b00c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_xgboost(X_train, y_train, X_test, y_test):\n",
    "    model = xgb.XGBClassifier(random_state=42, use_label_encoder=False, eval_metric='logloss')\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    y_pred = model.predict(X_test)\n",
    "    \n",
    "    metrics = {\n",
    "        'accuracy': accuracy_score(y_test, y_pred),\n",
    "        'precision': precision_score(y_test, y_pred),\n",
    "        'recall': recall_score(y_test, y_pred),\n",
    "        'f1': f1_score(y_test, y_pred),\n",
    "    }\n",
    "    \n",
    "    return model, metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b860405-0ca2-4fea-a935-52be4c8653d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_xgboost(X_train, y_train, X_test, y_test):\n",
    "    model = xgb.XGBClassifier(random_state=42, use_label_encoder=False, eval_metric='logloss')\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    y_pred = model.predict(X_test)\n",
    "    \n",
    "    metrics = {\n",
    "        'accuracy': accuracy_score(y_test, y_pred),\n",
    "        'precision': precision_score(y_test, y_pred),\n",
    "        'recall': recall_score(y_test, y_pred),\n",
    "        'f1': f1_score(y_test, y_pred),\n",
    "    }\n",
    "    \n",
    "    return model, metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b82409a-93fd-4885-833a-2e42bc1cddfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_xgboost(X_train, y_train, X_test, y_test):\n",
    "    model = xgb.XGBClassifier(random_state=42, use_label_encoder=False, eval_metric='logloss')\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    y_pred = model.predict(X_test)\n",
    "    \n",
    "    metrics = {\n",
    "        'accuracy': accuracy_score(y_test, y_pred),\n",
    "        'precision': precision_score(y_test, y_pred),\n",
    "        'recall': recall_score(y_test, y_pred),\n",
    "        'f1': f1_score(y_test, y_pred),\n",
    "    }\n",
    "    \n",
    "    print(\"Метрики XGBoost:\", metrics)\n",
    "    \n",
    "    return model, metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5feedca9-866d-45e9-8ce4-6c0d26bb0b5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_xgboost(X_train, y_train, X_test, y_test):\n",
    "    model = xgb.XGBClassifier(random_state=42, use_label_encoder=False, eval_metric='logloss')\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    y_pred = model.predict(X_test)\n",
    "    \n",
    "    metrics = {\n",
    "        'accuracy': accuracy_score(y_test, y_pred),\n",
    "        'precision': precision_score(y_test, y_pred),\n",
    "        'recall': recall_score(y_test, y_pred),\n",
    "        'f1': f1_score(y_test, y_pred),\n",
    "    }\n",
    "    \n",
    "    return model, metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3bcc8eb-e6c3-43c1-bc70-1ca708ef9883",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Georgiy\\Documents\\adult_income_classifier\\venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [12:24:43] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'accuracy': 0.8991392628558817,\n",
       " 'precision': 0.8891758123520551,\n",
       " 'recall': 0.9119399691017436,\n",
       " 'f1': 0.9004140335585095}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model, metrics = train_xgboost(X_train, y_train, X_test, y_test)\n",
    "metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea6a53bd-e151-4954-8c6b-c67a136c7f33",
   "metadata": {},
   "outputs": [],
   "source": [
    "import lightgbm as lgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0e5e6e9-3cd4-42ec-819c-e2f72ed20b13",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_lightgbm(X_train, y_train, X_test, y_test):\n",
    "    model = lgb.LGBMClassifier(random_state=42)\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    y_pred = model.predict(X_test)\n",
    "\n",
    "    metrics = {\n",
    "        'accuracy': accuracy_score(y_test, y_pred),\n",
    "        'precision': precision_score(y_test, y_pred),\n",
    "        'recall': recall_score(y_test, y_pred),\n",
    "        'f1': f1_score(y_test, y_pred),\n",
    "    }\n",
    "\n",
    "    print(\"Метрики LightGBM:\", metrics)\n",
    "    return model, metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "feb2eee7-91e9-4fbf-ad45-fd9780c2413f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 18123, number of negative: 18123\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003566 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1690\n",
      "[LightGBM] [Info] Number of data points in the train set: 36246, number of used features: 87\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "Метрики LightGBM: {'accuracy': 0.9010152284263959, 'precision': 0.8921018558480794, 'recall': 0.912381372765394, 'f1': 0.902127659574468}\n"
     ]
    }
   ],
   "source": [
    "model, metrics = train_lightgbm(X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78af2fd4-8c86-4295-b3d3-7d5a09d03185",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'accuracy': 0.9010152284263959,\n",
       " 'precision': 0.8921018558480794,\n",
       " 'recall': 0.912381372765394,\n",
       " 'f1': 0.902127659574468}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7580b76d-5294-4df3-9f9b-6945ea51162e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0932f321-0626-4ccb-9b81-2553947390dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_pytorch(X_train, y_train, X_test, y_test, epochs=20, batch_size=64, lr=0.001):\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    \n",
    "    X_train_tensor = torch.tensor(X_train.values, dtype=torch.float32).to(device)\n",
    "    y_train_tensor = torch.tensor(y_train.values.reshape(-1,1), dtype=torch.float32).to(device)\n",
    "    X_test_tensor = torch.tensor(X_test.values, dtype=torch.float32).to(device)\n",
    "    y_test_tensor = torch.tensor(y_test.values.reshape(-1,1), dtype=torch.float32).to(device)\n",
    "    \n",
    "    train_dataset = TensorDataset(X_train_tensor, y_train_tensor)\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "    \n",
    "    model = SimpleNN(X_train.shape[1]).to(device)\n",
    "    criterion = nn.BCELoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "    \n",
    "    model.train()\n",
    "    for epoch in range(epochs):\n",
    "        for xb, yb in train_loader:\n",
    "            optimizer.zero_grad()\n",
    "            preds = model(xb)\n",
    "            loss = criterion(preds, yb)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "    \n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        y_pred_prob = model(X_test_tensor).cpu().numpy()\n",
    "    y_pred = (y_pred_prob > 0.5).astype(int).flatten()\n",
    "    \n",
    "    metrics = {\n",
    "        'accuracy': accuracy_score(y_test, y_pred),\n",
    "        'precision': precision_score(y_test, y_pred),\n",
    "        'recall': recall_score(y_test, y_pred),\n",
    "        'f1': f1_score(y_test, y_pred),\n",
    "    }\n",
    "    \n",
    "    print(\"Метрики PyTorch NN:\", metrics)\n",
    "    return model, metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66b52891-65b4-403b-9423-b124db50fc48",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "age                               float64\n",
      "fnlwgt                            float64\n",
      "education.num                     float64\n",
      "capital.gain                      float64\n",
      "capital.loss                      float64\n",
      "                                   ...   \n",
      "native.country_Thailand              bool\n",
      "native.country_Trinadad&Tobago       bool\n",
      "native.country_United-States         bool\n",
      "native.country_Vietnam               bool\n",
      "native.country_Yugoslavia            bool\n",
      "Length: 96, dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(X_train.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1aa248f4-5117-4289-ae60-c1f04da8a99d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_pytorch(X_train, y_train, X_test, y_test, epochs=20, batch_size=64, lr=0.001):\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    \n",
    "    X_train = X_train.astype(np.float32)\n",
    "    X_test = X_test.astype(np.float32)\n",
    "    \n",
    "    X_train_tensor = torch.tensor(X_train.values, dtype=torch.float32).to(device)\n",
    "    y_train_tensor = torch.tensor(y_train.values.reshape(-1,1), dtype=torch.float32).to(device)\n",
    "    X_test_tensor = torch.tensor(X_test.values, dtype=torch.float32).to(device)\n",
    "    y_test_tensor = torch.tensor(y_test.values.reshape(-1,1), dtype=torch.float32).to(device)\n",
    "    \n",
    "    train_dataset = TensorDataset(X_train_tensor, y_train_tensor)\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "    \n",
    "    model = SimpleNN(X_train.shape[1]).to(device)\n",
    "    criterion = nn.BCELoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "    \n",
    "    model.train()\n",
    "    for epoch in range(epochs):\n",
    "        for xb, yb in train_loader:\n",
    "            optimizer.zero_grad()\n",
    "            preds = model(xb)\n",
    "            loss = criterion(preds, yb)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "    \n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        y_pred_prob = model(X_test_tensor).cpu().numpy()\n",
    "    y_pred = (y_pred_prob > 0.5).astype(int).flatten()\n",
    "    \n",
    "    metrics = {\n",
    "        'accuracy': accuracy_score(y_test, y_pred),\n",
    "        'precision': precision_score(y_test, y_pred),\n",
    "        'recall': recall_score(y_test, y_pred),\n",
    "        'f1': f1_score(y_test, y_pred),\n",
    "    }\n",
    "    \n",
    "    print(\"Метрики PyTorch NN:\", metrics)\n",
    "    return model, metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7412f3e7-e913-48a2-8c5d-f7e70f2286e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ad876a4-a26a-4ef6-9b65-43b1f965d14a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleNN(nn.Module):\n",
    "    def __init__(self, input_dim):\n",
    "        super(SimpleNN, self).__init__()\n",
    "        self.network = nn.Sequential(\n",
    "            nn.Linear(input_dim, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(64, 32),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(32, 1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return self.network(x)\n",
    "\n",
    "def train_pytorch(X_train, y_train, X_test, y_test, epochs=20, batch_size=64, lr=0.001):\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    \n",
    "    X_train = X_train.astype(np.float32)\n",
    "    X_test = X_test.astype(np.float32)\n",
    "    \n",
    "    X_train_tensor = torch.tensor(X_train.values, dtype=torch.float32).to(device)\n",
    "    y_train_tensor = torch.tensor(y_train.values.reshape(-1,1), dtype=torch.float32).to(device)\n",
    "    X_test_tensor = torch.tensor(X_test.values, dtype=torch.float32).to(device)\n",
    "    y_test_tensor = torch.tensor(y_test.values.reshape(-1,1), dtype=torch.float32).to(device)\n",
    "    \n",
    "    train_dataset = TensorDataset(X_train_tensor, y_train_tensor)\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "    \n",
    "    model = SimpleNN(X_train.shape[1]).to(device)\n",
    "    criterion = nn.BCELoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "    \n",
    "    model.train()\n",
    "    for epoch in range(epochs):\n",
    "        for xb, yb in train_loader:\n",
    "            optimizer.zero_grad()\n",
    "            preds = model(xb)\n",
    "            loss = criterion(preds, yb)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "    \n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        y_pred_prob = model(X_test_tensor).cpu().numpy()\n",
    "    y_pred = (y_pred_prob > 0.5).astype(int).flatten()\n",
    "    \n",
    "    metrics = {\n",
    "        'accuracy': accuracy_score(y_test, y_pred),\n",
    "        'precision': precision_score(y_test, y_pred),\n",
    "        'recall': recall_score(y_test, y_pred),\n",
    "        'f1': f1_score(y_test, y_pred),\n",
    "    }\n",
    "    \n",
    "    print(\"Метрики PyTorch NN:\", metrics)\n",
    "    return model, metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f2a280a-36c3-4b48-889d-bad000c4325a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Метрики PyTorch NN: {'accuracy': 0.8686824100640035, 'precision': 0.8615018394286951, 'recall': 0.8786139924961377, 'f1': 0.8699737762237763}\n",
      "{'accuracy': 0.8686824100640035, 'precision': 0.8615018394286951, 'recall': 0.8786139924961377, 'f1': 0.8699737762237763}\n"
     ]
    }
   ],
   "source": [
    "model, metrics = train_pytorch(X_train, y_train, X_test, y_test)\n",
    "print(metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76122c38-62d5-4b81-9df5-f254604c2c32",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'accuracy': 0.8686824100640035, 'precision': 0.8615018394286951, 'recall': 0.8786139924961377, 'f1': 0.8699737762237763}\n"
     ]
    }
   ],
   "source": [
    "print(metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "896cb7ea-f389-4aeb-a53e-0817633b3ceb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'accuracy': 0.8686824100640035,\n",
       " 'precision': 0.8615018394286951,\n",
       " 'recall': 0.8786139924961377,\n",
       " 'f1': 0.8699737762237763}"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca45ffef-4aeb-46ad-b4fe-472dbc4887b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6fbf617-97c6-4e67-bd93-29a77adfad29",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 243 candidates, totalling 729 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Georgiy\\Documents\\adult_income_classifier\\venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [12:38:34] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Лучшие параметры XGBoost: {'colsample_bytree': 0.6, 'learning_rate': 0.2, 'max_depth': 7, 'n_estimators': 200, 'subsample': 0.8}\n"
     ]
    }
   ],
   "source": [
    "model = xgb.XGBClassifier(random_state=42, use_label_encoder=False, eval_metric='logloss')\n",
    "\n",
    "param_grid = {\n",
    "    'n_estimators': [50, 100, 200],\n",
    "    'max_depth': [3, 5, 7],\n",
    "    'learning_rate': [0.01, 0.1, 0.2],\n",
    "    'subsample': [0.6, 0.8, 1],\n",
    "    'colsample_bytree': [0.6, 0.8, 1]\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(model, param_grid, cv=3, scoring='f1', n_jobs=-1, verbose=2)\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "best_xgb = grid_search.best_estimator_\n",
    "print(\"Лучшие параметры XGBoost:\", grid_search.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ff88161-96d3-44ed-9650-a7efe97dd80e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 729 candidates, totalling 2187 fits\n",
      "[LightGBM] [Info] Number of positive: 18123, number of negative: 18123\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006141 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1690\n",
      "[LightGBM] [Info] Number of data points in the train set: 36246, number of used features: 87\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Лучшие параметры LightGBM: {'colsample_bytree': 0.6, 'learning_rate': 0.2, 'max_depth': 7, 'n_estimators': 200, 'num_leaves': 50, 'subsample': 0.6}\n"
     ]
    }
   ],
   "source": [
    "model = lgb.LGBMClassifier(random_state=42)\n",
    "\n",
    "param_grid = {\n",
    "    'n_estimators': [50, 100, 200],\n",
    "    'max_depth': [3, 5, 7],\n",
    "    'learning_rate': [0.01, 0.1, 0.2],\n",
    "    'num_leaves': [31, 50, 100],\n",
    "    'subsample': [0.6, 0.8, 1],\n",
    "    'colsample_bytree': [0.6, 0.8, 1]\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(model, param_grid, cv=3, scoring='f1', n_jobs=-1, verbose=2)\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "best_lgbm = grid_search.best_estimator_\n",
    "print(\"Лучшие параметры LightGBM:\", grid_search.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e51522a1-32c6-4027-ab1c-01b90dd809a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import ParameterGrid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5833fdc-3037-495f-9eba-0dfa5d93e765",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleNN(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim=64, dropout=0.5):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(input_dim, hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(hidden_dim, 1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return self.net(x)\n",
    "\n",
    "def train_eval_nn(X_train, y_train, X_val, y_val, hidden_dim=64, lr=0.001, batch_size=64, epochs=10, dropout=0.5):\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    \n",
    "    model = SimpleNN(X_train.shape[1], hidden_dim=hidden_dim, dropout=dropout).to(device)\n",
    "    criterion = nn.BCELoss()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "    \n",
    "    # Преобразуем данные в тензоры и создаём DataLoader\n",
    "    train_ds = TensorDataset(\n",
    "        torch.tensor(X_train.values, dtype=torch.float32),\n",
    "        torch.tensor(y_train.values.reshape(-1,1), dtype=torch.float32)\n",
    "    )\n",
    "    train_loader = DataLoader(train_ds, batch_size=batch_size, shuffle=True)\n",
    "    \n",
    "    model.train()\n",
    "    for epoch in range(epochs):\n",
    "        for xb, yb in train_loader:\n",
    "            xb, yb = xb.to(device), yb.to(device)\n",
    "            pred = model(xb)\n",
    "            loss = criterion(pred, yb)\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "    \n",
    "    # Оценка на валидации\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        X_val_t = torch.tensor(X_val.values, dtype=torch.float32).to(device)\n",
    "        y_val_np = y_val.values\n",
    "        preds = model(X_val_t).cpu().numpy()\n",
    "        preds_labels = (preds > 0.5).astype(int)\n",
    "    \n",
    "    f1 = f1_score(y_val_np, preds_labels)\n",
    "    return model, f1\n",
    "\n",
    "def hyperparam_search_nn(X_train, y_train, X_val, y_val):\n",
    "    param_grid = {\n",
    "        'hidden_dim': [32, 64, 128],\n",
    "        'lr': [0.001, 0.0005],\n",
    "        'batch_size': [32, 64],\n",
    "        'dropout': [0.3, 0.5]\n",
    "    }\n",
    "    \n",
    "    best_f1 = 0\n",
    "    best_params = None\n",
    "    best_model = None\n",
    "    \n",
    "    for params in ParameterGrid(param_grid):\n",
    "        print(f\"Тестируем параметры: {params}\")\n",
    "        model, f1 = train_eval_nn(\n",
    "            X_train, y_train, X_val, y_val,\n",
    "            hidden_dim=params['hidden_dim'],\n",
    "            lr=params['lr'],\n",
    "            batch_size=params['batch_size'],\n",
    "            dropout=params['dropout'],\n",
    "            epochs=10\n",
    "        )\n",
    "        print(f\"F1: {f1:.4f}\")\n",
    "        \n",
    "        if f1 > best_f1:\n",
    "            best_f1 = f1\n",
    "            best_params = params\n",
    "            best_model = model\n",
    "    \n",
    "    print(\"\\nЛучшие параметры:\", best_params)\n",
    "    print(\"Лучшее F1:\", best_f1)\n",
    "    return best_model, best_params, best_f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c500fa17-fa3d-416a-896e-d249ee38fb4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleNN(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim=64, dropout=0.5):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(input_dim, hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(hidden_dim, 1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return self.net(x)\n",
    "\n",
    "def train_eval_nn(X_train, y_train, X_val, y_val, hidden_dim=64, lr=0.001, batch_size=64, epochs=10, dropout=0.5):\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    \n",
    "    model = SimpleNN(X_train.shape[1], hidden_dim=hidden_dim, dropout=dropout).to(device)\n",
    "    criterion = nn.BCELoss()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "    \n",
    "    # Преобразуем данные в тензоры и создаём DataLoader\n",
    "    train_ds = TensorDataset(\n",
    "        torch.tensor(X_train.values, dtype=torch.float32),\n",
    "        torch.tensor(y_train.values.reshape(-1,1), dtype=torch.float32)\n",
    "    )\n",
    "    train_loader = DataLoader(train_ds, batch_size=batch_size, shuffle=True)\n",
    "    \n",
    "    model.train()\n",
    "    for epoch in range(epochs):\n",
    "        for xb, yb in train_loader:\n",
    "            xb, yb = xb.to(device), yb.to(device)\n",
    "            pred = model(xb)\n",
    "            loss = criterion(pred, yb)\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "    \n",
    "    # Оценка на валидации\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        X_val_t = torch.tensor(X_val.values, dtype=torch.float32).to(device)\n",
    "        y_val_np = y_val.values\n",
    "        preds = model(X_val_t).cpu().numpy()\n",
    "        preds_labels = (preds > 0.5).astype(int)\n",
    "    \n",
    "    f1 = f1_score(y_val_np, preds_labels)\n",
    "    return model, f1\n",
    "\n",
    "X_train = X_train.astype(np.float32)\n",
    "X_test = X_test.astype(np.float32)\n",
    "\n",
    "\n",
    "def hyperparam_search_nn(X_train, y_train, X_val, y_val):\n",
    "    param_grid = {\n",
    "        'hidden_dim': [32, 64, 128],\n",
    "        'lr': [0.001, 0.0005],\n",
    "        'batch_size': [32, 64],\n",
    "        'dropout': [0.3, 0.5]\n",
    "    }\n",
    "    \n",
    "    best_f1 = 0\n",
    "    best_params = None\n",
    "    best_model = None\n",
    "    \n",
    "    for params in ParameterGrid(param_grid):\n",
    "        print(f\"Тестируем параметры: {params}\")\n",
    "        model, f1 = train_eval_nn(\n",
    "            X_train, y_train, X_val, y_val,\n",
    "            hidden_dim=params['hidden_dim'],\n",
    "            lr=params['lr'],\n",
    "            batch_size=params['batch_size'],\n",
    "            dropout=params['dropout'],\n",
    "            epochs=10\n",
    "        )\n",
    "        print(f\"F1: {f1:.4f}\")\n",
    "        \n",
    "        if f1 > best_f1:\n",
    "            best_f1 = f1\n",
    "            best_params = params\n",
    "            best_model = model\n",
    "    \n",
    "    print(\"\\nЛучшие параметры:\", best_params)\n",
    "    print(\"Лучшее F1:\", best_f1)\n",
    "    return best_model, best_params, best_f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b95caa10-908e-44aa-91ff-f56a0aa21db0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Тестируем параметры: {'batch_size': 32, 'dropout': 0.3, 'hidden_dim': 32, 'lr': 0.001}\n",
      "F1: 0.8658\n",
      "Тестируем параметры: {'batch_size': 32, 'dropout': 0.3, 'hidden_dim': 32, 'lr': 0.0005}\n",
      "F1: 0.8608\n",
      "Тестируем параметры: {'batch_size': 32, 'dropout': 0.3, 'hidden_dim': 64, 'lr': 0.001}\n",
      "F1: 0.8699\n",
      "Тестируем параметры: {'batch_size': 32, 'dropout': 0.3, 'hidden_dim': 64, 'lr': 0.0005}\n",
      "F1: 0.8630\n",
      "Тестируем параметры: {'batch_size': 32, 'dropout': 0.3, 'hidden_dim': 128, 'lr': 0.001}\n",
      "F1: 0.8720\n",
      "Тестируем параметры: {'batch_size': 32, 'dropout': 0.3, 'hidden_dim': 128, 'lr': 0.0005}\n",
      "F1: 0.8669\n",
      "Тестируем параметры: {'batch_size': 32, 'dropout': 0.5, 'hidden_dim': 32, 'lr': 0.001}\n",
      "F1: 0.8650\n",
      "Тестируем параметры: {'batch_size': 32, 'dropout': 0.5, 'hidden_dim': 32, 'lr': 0.0005}\n",
      "F1: 0.8592\n",
      "Тестируем параметры: {'batch_size': 32, 'dropout': 0.5, 'hidden_dim': 64, 'lr': 0.001}\n",
      "F1: 0.8634\n",
      "Тестируем параметры: {'batch_size': 32, 'dropout': 0.5, 'hidden_dim': 64, 'lr': 0.0005}\n",
      "F1: 0.8572\n",
      "Тестируем параметры: {'batch_size': 32, 'dropout': 0.5, 'hidden_dim': 128, 'lr': 0.001}\n",
      "F1: 0.8659\n",
      "Тестируем параметры: {'batch_size': 32, 'dropout': 0.5, 'hidden_dim': 128, 'lr': 0.0005}\n",
      "F1: 0.8659\n",
      "Тестируем параметры: {'batch_size': 64, 'dropout': 0.3, 'hidden_dim': 32, 'lr': 0.001}\n",
      "F1: 0.8635\n",
      "Тестируем параметры: {'batch_size': 64, 'dropout': 0.3, 'hidden_dim': 32, 'lr': 0.0005}\n",
      "F1: 0.8597\n",
      "Тестируем параметры: {'batch_size': 64, 'dropout': 0.3, 'hidden_dim': 64, 'lr': 0.001}\n",
      "F1: 0.8662\n",
      "Тестируем параметры: {'batch_size': 64, 'dropout': 0.3, 'hidden_dim': 64, 'lr': 0.0005}\n",
      "F1: 0.8598\n",
      "Тестируем параметры: {'batch_size': 64, 'dropout': 0.3, 'hidden_dim': 128, 'lr': 0.001}\n",
      "F1: 0.8696\n",
      "Тестируем параметры: {'batch_size': 64, 'dropout': 0.3, 'hidden_dim': 128, 'lr': 0.0005}\n",
      "F1: 0.8679\n",
      "Тестируем параметры: {'batch_size': 64, 'dropout': 0.5, 'hidden_dim': 32, 'lr': 0.001}\n",
      "F1: 0.8625\n",
      "Тестируем параметры: {'batch_size': 64, 'dropout': 0.5, 'hidden_dim': 32, 'lr': 0.0005}\n",
      "F1: 0.8579\n",
      "Тестируем параметры: {'batch_size': 64, 'dropout': 0.5, 'hidden_dim': 64, 'lr': 0.001}\n",
      "F1: 0.8672\n",
      "Тестируем параметры: {'batch_size': 64, 'dropout': 0.5, 'hidden_dim': 64, 'lr': 0.0005}\n",
      "F1: 0.8609\n",
      "Тестируем параметры: {'batch_size': 64, 'dropout': 0.5, 'hidden_dim': 128, 'lr': 0.001}\n",
      "F1: 0.8658\n",
      "Тестируем параметры: {'batch_size': 64, 'dropout': 0.5, 'hidden_dim': 128, 'lr': 0.0005}\n",
      "F1: 0.8644\n",
      "\n",
      "Лучшие параметры: {'batch_size': 32, 'dropout': 0.3, 'hidden_dim': 128, 'lr': 0.001}\n",
      "Лучшее F1: 0.872040946896993\n"
     ]
    }
   ],
   "source": [
    "model, best_params, best_f1 = hyperparam_search_nn(X_train, y_train, X_test, y_test)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": 3
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
